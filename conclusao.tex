\chapter[Considerações Finais]{Considerações Finais}

Neste trabalho foi apresentado um método de seleção de variáveis \textit{stepwise} utilizando o erro de validação cruzada \textit{leave-one-out} (LOOCV) em regressores lineares como métrica de performance. O algoritmo proposto faz uso de identidades algébricas conhecidas na literatura para determinar, de maneira incremental, o erro de LOOCV ao se acrescentar uma variável. Dessa maneira elimina-se a necessidade do ajuste de novos modelos lineares a cada subconjunto de variáveis avaliado.

Os resultados obtidos sugerem a manutenção ou melhora da performance nos bancos de dados considerados ao se utilizar o subconjunto de entradas proposto pelo algoritmo. Além disso, tais subconjuntos são, em todos os casos avaliados, significativamente menores que o total disponível, reduzindo assim o custo computacional e acelerando o treinamento dos modelos.

Diversas técnicas para seleção de variáveis \textit{stepwise} são conhecidas na literatura, porém essas, em geral, utilizam métricas que se baseiam no comportamento assintótico do conjunto de variáveis e presumem diversas restrições em relação ao conjunto de dados e ao modelo a ser desenvolvido. Utilizar o erro de validação cruzada como métrica permite o relaxamento dessas restrições.

A necessidade do armazenamento de uma matriz quadrada da dimensão do tamanho do conjunto amostral é um fator limitante no método proposto. Uma possível solução para tal limitação é a utilização de um número menor de amostras para a seleção de variáveis. Porém a determinação desse número exige ainda um estudo de complexidade amostral (\textit{sample complexity}), aplicando-se teorias tais como complexidade de Rademacher para determinação dos limiares do erro de generalização. Porém tal estudo foge ao escopo desse trabalho.

Por fim, a utilização de regressões lineares é também um fator limitante, uma vez que esses modelos podem falhar em capturar algumas relações não-lineares. Uma possível maneira de minimizar esse problema é utilizar o truque de kernel (\textit{kernel trick})\cite{peaking_phenomenon}, isto é, a aplicar uma função não linear aos dados e utilizar esses dados como entradas no método proposto. Dessa maneira, o algoritmo continua sendo linear em relação às variáveis transformadas, porém se torna não linear em relação aos dados originais.