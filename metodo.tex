\chapter[Desenvolvimento e Metodologia]{Desenvolvimento e Metodologia}

\section{Algoritmo}

\subsection{Seleção de Variáveis \textit{Stepwise}}

O algoritmo proposto nesse trabalho é baseado no método de seleção de variáveis \textit{stepwise} 
(\textit{Stepwise Selection}), comumente utilizado em conjunto com modelos de regressão linear. É um método de
\textit{greedy search}, onde, a cada iteração, a variável que apresentar o melhor ganho de performance é 
adicionada ao conjunto de entradas. 

O modelo é construido incrementalmente até que não haja mais melhora de performance ao acrescentar alguma das 
variáveis restantes ou não haja mais variáveis para serem consideradas. O método é descrito em pseudocódigo no 
algoritmo \ref{alg:stepwiseselection}
\\


\begin{algorithm}[H]
    \caption{\textit{Forward Stepwise Selection} (FSS)}
    \KwIn{$variáveis$: lista contendo as variáveis disponíveis;}
    \KwIn{$saídas$: lista contendo as saídas do modelo;}
    \KwOut{$selecionadas$: lista de variáveis relevantes.}
    $selecionadas \gets \{\ \}$ \\
    $melhorErro \gets \infty$ \\
    \Repeat{$variáveis == \{\ \}$ ou (critério de parada)}
    {   
        $melhorVariável \gets NULL$ \\     
        \ForEach{elemento $var$ em $variáveis$}{
            $entradas \gets (var \cup selecionadas)$ \\
            $model \gets ajuste(entradas,saídas)$ \\
            $erro \gets avalia(model,entradas,saídas)$ \\
            \If{$erro <melhorErro$}{
                $melhorErro \gets erro$\\
                $melhorVariável \gets var$ \\     
            }
        }
        $selecionadas \gets (melhorVariável \cup selecionadas)$ \\
        $variáveis \gets (variáveis \setminus \{melhorVariável\})$ \\
    }
    \label{alg:stepwiseselection}
\end{algorithm}

\qquad

Esse algoritmo apresenta uma redução expressiva na quantidade de modelos ajustados em relação ao método da 
seleção do melhor subconjunto, que é um algoritmo de busca exaustiva, onde todas as combinações possíveis das 
variáveis de entrada são testadas. Na primeira iteração, o modelo nulo deve ser ajustado, em seguida, todas as 
$p$ varíaveis devem ser avaliadas e, a cada iteração posterior, uma delas é retirada. Portanto o total de 
modelos ajustados pode ser descrito pela eq. \ref{eq:total_models}

\begin{equation}
    Ajustes = 1 + \sum^{p-1}_{k = 0} (p-k) = 1 + \dfrac{p (p+1)}{2} =  \dfrac{1}{2} (p^2 + p  + 2)
    \label{eq:total_models}
\end{equation}

Porém, ao contrário do método da seleção do melhor subconjunto, não há garantia que o subconjunto determinado é 
a combinação ótima das variáveis \cite[p. 208]{intro_stat_learn}.

A utilização de uma métrica de avaliação que considere simplesmente os dados ajustados não é adequada, 
uma vez que, nessa situação, o incremento de uma variável no modelo sempre acarretará em uma melhora no erro de 
treinamento, porém não necessariamente na capacidade de generalização do modelo.

Algumas técnicas tentam determinar o erro de generalização através do ajuste do erro de treinamento, tais como o 
critério de Informação de Akaike (AIC) ou critério de informação Bayesiano (BIC), porém elas se baseiam no 
comportamento assintótico, isto é, quando a quantidade de amostras é bastante elevada.

Uma alternativa a essas técnicas é a utilização de validação cruzada, onde o modelo selecionado é aquele que 
apresenta a melhor performance no conjunto de testes. Dessa maneira, obtém-se diretamente uma estimativa do erro 
de generalização, além de se assumir menos condições em relação ao modelo e aos dados utilizados. O grande 
desafio dessa técnica é o custo computacional da validação cruzada que, quando associado ao custo do método de 
seleção de variáveis \textit{stepwise} pode tornar proibitiva sua implementação.

Em especial, a utilização desse método associada ao \textit{leave-one-out cross-validation} resultaria no ajuste 
de $\sfrac{1}{2}(p^2+p+2)(N-1)$ modelos, tornando o algoritmo computacionalmente inviável.

\subsection{Método Incremental}

Para minimizar o problema do custo computacional, o método implementado utiliza o resultado apresentado na eq. 
\ref{eq:LOOCV_error} para calcular o erro de validação cruzada sem a necessidade de cálcular $N-1$ modelos de 
regressão linear. Além disso, o cálculo da matriz de aniquilação é realizado de maneira incremental, conforme 
deduzido na eq. \ref{eq:inc_matrix_iterativa}.

O algoritmo \ref{alg:stepwiseselection} é então modificado para realizar o cálculo incremental, utilizando 
LOOCV como métrica para seleção dos das variáveis e atualização incremental do modelo.

\qquad

\begin{algorithm}[H]
    \caption{\textit{Forward Stepwise Incremental Selection}}
    \KwIn{$variáveis$: lista contendo as variáveis disponíveis;}
    \KwIn{$saídas$: lista contendo as saídas do modelo;}
    \KwOut{$selecionadas$: lista de variáveis relevantes.}
    
    $selecionadas \gets \{\ \}$ \\
    $melhorErro \gets \infty$ \\
    $M \gets I_N$ \\

    \Repeat{$variáveis == \{\ \}$ ou (critério de parada)}
    { 
        $melhorVariável \gets NULL$ \\
        \ForEach{elemento $var$ em $variáveis$}{
            $M' \gets ajusteIncremental(M,var)$ \\
            $erro  \gets erroLOOCV(M,saídas)$ \\
            \If{$erro <melhorErro$}{
                $melhorErro \gets erro$\\
                $melhorVariável \gets var$ \\                
                $melhorM \gets M' $  \\
            }
        }
        $M \gets melhorM $ \\
        $selecionadas \gets (melhorVariável \cup selecionadas)$ \\
        $variáveis \gets (variáveis \setminus \{melhor_{variável}\})$ \\
    }
    \label{alg:incstepwiseselection}
\end{algorithm}



\section{Testes e Validação}

\subsection{Conjuntos de dados}

Para teste e validação do algoritmo desenvolvido, utilizou-se três bancos de dados conhecidos na literatura, 
especificados na tabela \ref{tbl:datasets}.
\begin{table}[H]
    \caption{Conjuntos de dados utilizados para validação.}
    \centering
    \begin{tabular}{@{}lll@{}}
    \toprule
    Nome                           & Variáveis & Amostras \\ \midrule
    \textit{Forest Fires}          & 12        & 517      \\
    \textit{USA Housing Dataset}   & 80        & 1460     \\
    \textit{Wiscoin Breast Cancer} & 32        & 194      \\ \bottomrule
    \end{tabular}
    \label{tbl:datasets}
\end{table}

\subsubsection{Preprocessamento}

De maneira geral, em um conjunto de amostras, as variáveis apresentam diferentes unidades, magnitudes e escalas, 
isso dificulta a comparação de valores e pode prejudicar o treinamento de modelos. Por isso é comum aplicar uma 
transformação nos dados, de maneira a torna-los comparáveis entre si (\textit{feature scaling}), além de 
facilitar a detecção de \textit{outliers}.

Embora o algoritmo utilizado se baseie em regressões lineares que, em sua forma mais simples, são robustas em 
relação a magnitude das variáveis, a adição do termo de regressão penaliza o crescimento do vetor de parâmetros, 
tornando o modelo sensivel à diferença de magnitudes entre variáveis.

Nesse trabalho, todas as variáveis foram normalizadas, de maneira a se obter entradas e saídas que apresentam 
média nula e desvio padrão unitário. Tal transformação é conhecida como \textit{z-score} (eq. \ref{eq:z-score}).

\begin{equation}
    X_p = \frac{ X_p - \bar{X_p} }{SD(X_p)}
    \label{eq:z-score}
\end{equation}

Além disso, uma variável de entrada com valor unitário foi adicionada posteriormente a cada conjunto de dados, 
permitindo a consideração do termo livre ($w_0$) nos cálculos de maneira transparente.

\subsection{Metodologia de Validação}

Com o intuito de identificar um subconjunto ótimo de variáveis para cada conjunto de dados, o algoritmo 
desenvolvido foi empregado e o erro de validação cruzada, conforme a eq. \ref{eq:LOOCV_error}, foi registrado 
ao final de cada iteração. Dessa maneira é possível analisar o efeito da inclusão de uma nova variável na 
capacidade de generalização do modelo e avaliar até onde é benéfico o aumento de uma nova dimensão.

Além disso, verificou-se a influência do número de amostras e dimensões no modelo. Para isso, o procedimento 
anterior foi repetido em subconjuntos de menos amostras ($50\%$, $33\%$, $25\%$), selecionadas aleatoriamente 
múltiplas vezes. O erro inicial médio de cada um desses experimentos foi deslocado para zero, de maneira a 
permitir a comparação dos resultados em função do aumento do número de dimensões.

\subsection{Estudo de Caso: Vallourec}

